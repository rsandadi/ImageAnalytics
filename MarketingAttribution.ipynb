{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1506816000\n",
      "1541116799\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "start_timestamp = int(datetime.strptime(\"2017-10-01\",\n",
    "                                        \"%Y-%m-%d\").timestamp())\n",
    "\n",
    "end_timestamp = int(datetime.strptime(\"2018-11-01\", \"%Y-%m-%d\").replace(\n",
    "                                          hour=23, minute=59, second=59\n",
    "                                          ).timestamp())\n",
    "print(start_timestamp)\n",
    "print(end_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "SELECT *, RANK() OVER (PARTITION BY main_Id ORDER BY visitStartTime ASC) AS seq2 \n",
      "FROM `emirates-ga-cloud-staging.test_attribution.uk_data_jan_onwards_data` \n",
      "WHERE main_Id IN ( SELECT main_Id FROM `emirates-ga-cloud-staging.test_attribution.uk_data_jan_onwards_data` \n",
      "WHERE visitStartTime BETWEEN 1506816000 AND 1541116799 )\n"
     ]
    }
   ],
   "source": [
    "query=\"\"\" \n",
    "SELECT *, RANK() OVER (PARTITION BY main_Id ORDER BY visitStartTime ASC) AS seq2 \n",
    "FROM `emirates-ga-cloud-staging.test_attribution.uk_data_jan_onwards_data` \n",
    "WHERE main_Id IN ( SELECT main_Id FROM `emirates-ga-cloud-staging.test_attribution.uk_data_jan_onwards_data` \n",
    "WHERE visitStartTime BETWEEN \"\"\" +str(start_timestamp)+\"\"\" AND \"\"\"+str(end_timestamp)+\"\"\" )\"\"\"\n",
    "\n",
    "print(query)\n",
    "import google.datalab.bigquery as bq\n",
    "chunks = bq.Query(query).execute().result().to_dataframe()\n",
    "chunks.head()\n",
    "chunks.to_csv(\"BQData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_channels(channels):\n",
    "    channels = [x.replace(\" \", \"\") for x in list(channels)]\n",
    "    return \" > \".join(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "chunks1 = pd.read_csv(\"raj.csv\", chunksize=1000000,\n",
    "\t\t\t\t\tdtype = {\n",
    "\t\t\t\t\t'fullVisitorId': 'str',\n",
    "\t\t\t\t\t'main_Id': 'str',\n",
    "\t\t\t\t\t'visitStartTime': 'int32',\n",
    "\t\t\t\t\t'visitStartTime': 'int32',\n",
    "\t\t\t\t\t'sourceChannel': 'object',\n",
    "\t\t\t\t\t'Platform': 'object',\n",
    "\t\t\t\t\t'medium': 'object',\n",
    "\t\t\t\t\t'source': 'object',\n",
    "\t\t\t\t\t'campaign': 'object',\n",
    "\t\t\t\t\t'keyword': 'object',\n",
    "\t\t\t\t\t'adContent': 'object',\n",
    "\t\t\t\t\t'revenue': 'float32',\n",
    "\t\t\t\t\t'transaction_time': 'float32',\n",
    "\t\t\t\t\t'seq': 'int8'\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-7fa881479862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sourceChannel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m      \u001b[0;31m#Exclude Operational Emails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reformatting data...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Operational'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'channels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Direct'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'interaction_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'visitStartTime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "for chunk in chunks1:\n",
    "    chunk['channels'] = chunk['sourceChannel']\n",
    "     #Exclude Operational Emails\n",
    "    print(\"Reformatting data...\", file=sys.stderr)\n",
    "    chunk.loc[(chunk['channels'].str.contains('Operational')), 'channels'] = 'Direct'\n",
    "    chunk['interaction_date'] = pd.to_datetime(chunk['visitStartTime'], unit = 's')\n",
    "    chunk['interaction_date'] = chunk['interaction_date'].dt.date.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/__main__.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/__main__.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/__main__.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/__main__.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#print(chunk.loc[chunk[\"channels\"] == \"Direct\"])\n",
    "#chunk.columns\n",
    "# Reclassify App Direct\n",
    "#print(\"Reclassifying App Direct..\", file=sys.stderr)\n",
    "chunk['Platform'] = chunk['Platform'].astype(str)\n",
    "chunk.loc[(chunk['Platform'].str.contains('iPhone')), 'channels'] = 'Direct'\n",
    "chunk.loc[(chunk['Platform'].str.contains('Android')), 'channels'] = 'Direct'\n",
    "chunk.loc[(chunk['Platform'].str.contains('iPad')), 'channels'] = 'Direct'   \n",
    "chunk.loc[(chunk['Platform'].str.contains(' ')), 'channels'] = 'Direct'   \n",
    "chunk.loc[(chunk['channels'].str.contains('App_Direct')), 'channels'] = 'Direct'   \n",
    "temp_2 = (chunk.groupby('main_Id')['visitStartTime'].nunique()).reset_index()\n",
    "temp_2 = temp_2[temp_2['visitStartTime'] < 2]\n",
    "chunk.loc[(chunk['Platform'].str.contains('iPhone|Android|iPad')) & (chunk['main_Id'].isin(temp_2['main_Id'])), 'channels'] = 'App_Direct'\n",
    "\n",
    "# Use source within Display Prospecting, to attribute revenue to the specific Display Publisher\n",
    "#print(\"Reformat Display Publishers\", file=sys.stderr)\n",
    "chunk.loc[(chunk['channels'].str.contains('Prospecting')) & (chunk['source'].str.contains('kayak')) , 'channels'] = 'DisplayProspectingKayak'\n",
    "chunk.loc[(chunk['channels'].str.contains('Prospecting')) & (chunk['source'].str.contains('tripadvisor')) , 'channels'] = 'DisplayProspectingTripAdvisor'\n",
    "chunk.loc[(chunk['channels'].str.contains('Prospecting')) & (chunk['source'].str.contains('skyscanner')) , 'channels'] = 'DisplayProspectingSkyscanner'\n",
    "chunk.loc[(chunk['channels'].str.contains('Prospecting')) & (chunk['source'].str.contains('travelzoo')) , 'channels'] = 'DisplayProspectingTravelzoo'\n",
    "\n",
    "# Split into converting and non-converting journeys\n",
    "#print(\"Splitting by converting/non-converting\", file=sys.stderr)\n",
    "visitor_list = (chunk.groupby(['main_Id'])['transactionId'].count()).reset_index()\n",
    "visitor_list = visitor_list[visitor_list['transactionId'] > 0]\n",
    "conv = chunk[chunk['main_Id'].isin(visitor_list['main_Id'])]\n",
    "non_conv = chunk[~(chunk['main_Id'].isin(visitor_list['main_Id']))]\n",
    "\n",
    "conv.loc[conv['revenue'].notnull() & conv['transactionId'].isnull(), 'revenue'] = np.nan\n",
    "conv[\"transaction_time\"] = conv.groupby([\"main_Id\"])['transaction_time'].transform(lambda x: x.bfill())\n",
    "conv['transaction_date'] = pd.to_datetime(conv['transaction_time'], unit = 's')\n",
    "conv['transaction_date'] = conv['transaction_date'].dt.date.astype(str)\n",
    "conv[\"transactionId\"] = conv.groupby([\"main_Id\", \"transaction_date\"])['transactionId'].transform(lambda x: x.bfill())\n",
    "conv_temp = (conv.groupby(['transaction_time', \"transactionId\"])['revenue'].max()).reset_index()\n",
    "conv = conv.merge(conv_temp, how = 'outer', on = ['transaction_time', \"transactionId\"])\n",
    "conv['revenue'] = conv['revenue_y']\n",
    "conv = conv[conv['transaction_time'].notnull()]\n",
    "conv = conv.dropna(subset=['revenue'])\n",
    "conv = conv.drop_duplicates(keep='last')\n",
    "\n",
    "### Implement 90 day lookback window\n",
    "#print(\"Implement lookback window for converting journeys\", file=sys.stderr)\n",
    "conv['Time_To_Transaction_Days'] = (conv['transaction_time'] - conv['visitStartTime'])/(60*60*24)\n",
    "conv = conv[conv['Time_To_Transaction_Days'] <= 90]\n",
    "\n",
    "# Rank over interactions for new and returning customers\n",
    "conv['rank'] = conv.groupby('main_Id')['transaction_time'].rank(method='dense')\n",
    "\n",
    "# Split by new and returning customers\n",
    "#print(\"Splitting by new/returning\", file=sys.stderr)\n",
    "conv[\"state\"] = \"new\"\n",
    "conv.loc[conv['rank'] > 1, \"state\"] = \"returning\"\n",
    "\n",
    "#print(\"Grouping new/returning...\", file=sys.stderr)\n",
    "conv = (conv.groupby([\"transaction_date\", \"state\", 'transactionId', 'revenue'])['channels'].apply(combine_channels)).reset_index()\n",
    "\n",
    "conv['var_value'] = conv['revenue']/1000000.0\n",
    "\n",
    "# Select only the rows we want\n",
    "conv = conv[['transaction_date', 'state', 'channels', 'var_value']]\n",
    "\n",
    "# SPLIT BY PPC\n",
    "PPC_start = conv[conv['channels'].str.contains(\"PPCBrand\")]\n",
    "no_PPC = conv[~conv['channels'].str.contains(\"PPCBrand\")]\n",
    "len_PPC = int(len(PPC_start))\n",
    "PPC_TV = int(0.02 * len_PPC)\n",
    "\n",
    "# Picks SIZE numbers from 0 to a\n",
    "if(len_PPC>0):\n",
    "   \tchosen_idx=np.random.choice(len_PPC,replace=False,size=PPC_TV)\n",
    "   \tPPC_start.iloc[chosen_idx, PPC_start.columns.get_loc('channels')] = 'Tac_Imp' + ' > ' + PPC_start['channels']\n",
    "\n",
    "all_dfs = [PPC_start, no_PPC]\n",
    "\n",
    "# Concatenate all te dataframes back together\n",
    "conv = pd.concat(all_dfs).reset_index(drop=True)  \n",
    "\n",
    "#Count Total value\n",
    "conv_grouped = (conv.groupby(['transaction_date', 'state', 'channels'])['var_value'].agg(['sum', 'count'])).reset_index()\n",
    "#print(\"conversions final data file\", file=sys.stderr)\n",
    "conv_grouped.to_csv('resultConv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transaction_date', 'state', 'channels', 'var_value'], dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(chunk.loc[chunk[\"channels\"] == \"DisplayProspectingKayak\"])\n",
    "conv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
